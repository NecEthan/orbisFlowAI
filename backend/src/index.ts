import express, { Request, Response } from "express";
import OpenAI from "openai";
import dotenv from "dotenv";
import multer from "multer";
import uploadDocsRouter from "./routes/upload-docs";
import askQuestionRouter from "./routes/ask";
import { Readable } from "stream";
import { File as NodeFile } from "node:buffer";
import path from "path";
import fs from "fs";
import FormData from "form-data";
import axios from "axios";

// ðŸ§  Fix for Node.js File global (for OpenAI file uploads)
(globalThis as any).File = NodeFile;

// Load environment variables
dotenv.config({ path: "./.env" });

// Initialize OpenAI client
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY!,
});

const upload = multer({
  storage: multer.memoryStorage(),
  limits: { fileSize: 500 * 1024 * 1024 }, // 500MB
});

const app = express();
const port = process.env.PORT || 3001;

// Your OpenAI vector store ID
const VECTOR_STORE_ID = "vs_68f3ba8f1ea48191bb6679e9d74dd719";

// Increase body parser limits
app.use(express.json({ limit: "500mb" }));
app.use(express.urlencoded({ limit: "500mb", extended: true }));

// Mount routers (if you still use them)
app.use("/upload-docs", uploadDocsRouter);
app.use("/ask-question", askQuestionRouter);

// Enable CORS for Figma plugin or local frontend
app.use((req, res, next) => {
  res.header("Access-Control-Allow-Origin", "*");
  res.header(
    "Access-Control-Allow-Headers",
    "Origin, X-Requested-With, Content-Type, Accept, Authorization"
  );
  res.header("Access-Control-Allow-Methods", "GET, POST, PUT, DELETE, OPTIONS");
  if (req.method === "OPTIONS") return res.sendStatus(200);
  next();
});

// Helper: Buffer â†’ Readable Stream
function bufferToStream(buffer: Buffer) {
  const stream = new Readable();
  stream.push(buffer);
  stream.push(null);
  return stream;
}

/**
 * ðŸ§© Upload PDF endpoint
 * Uploads file to OpenAI â†’ adds it to your existing vector store
 */
app.post("/api/upload-pdf", upload.single("file"), async (req: Request, res: Response) => {
  console.log("ðŸ“¥ /api/upload-pdf called");

  try {
    if (!req.file) {
      return res.status(400).json({ error: "No file uploaded" });
    }

    console.log("âœ… File received:", req.file.originalname);
    console.log("ðŸ“Š File details:", {
      size: req.file.size,
      originalname: req.file.originalname,
      mimetype: req.file.mimetype,
    });

    // Save file temporarily
    const tempPath = path.join("/tmp", req.file.originalname);
    fs.writeFileSync(tempPath, req.file.buffer);

    // ðŸ§© Proper multipart/form-data for OpenAI upload
    const formData = new FormData();
    formData.append("file", fs.createReadStream(tempPath));
    formData.append("purpose", "assistants");

    console.log("ðŸ”„ Uploading file to OpenAI...");

    const uploadRes = await axios.post("https://api.openai.com/v1/files", formData, {
      headers: {
        Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
        ...formData.getHeaders(),
      },
    });

    const uploadedFile = uploadRes.data;
    console.log("ðŸ“„ File uploaded to OpenAI:", uploadedFile.id);

    // Delete temp file
    fs.unlinkSync(tempPath);

    // âž• Add file to your existing vector store
    console.log(`ðŸ”— Adding file ${uploadedFile.id} to vector store ${VECTOR_STORE_ID}...`);
    await axios.post(
      `https://api.openai.com/v1/vector_stores/${VECTOR_STORE_ID}/files`,
      { file_id: uploadedFile.id },
      {
        headers: { Authorization: `Bearer ${process.env.OPENAI_API_KEY}` },
      }
    );

    console.log(`âœ… File ${uploadedFile.id} added to vector store ${VECTOR_STORE_ID}`);

    res.json({
      message: "âœ… File uploaded and added to vector store successfully",
      openaiFileId: uploadedFile.id,
      vectorStoreId: VECTOR_STORE_ID,
      fileName: req.file.originalname,
      fileSize: req.file.size,
    });
  } catch (err: any) {
    console.error("ðŸ’¥ Upload error:", err.response?.data || err.message);
    res.status(500).json({
      error: err.message || "Unexpected server error",
      details: err.response?.data || err.stack,
    });
  }
});

/**
 * ðŸ§  Test OpenAI connection
 */
app.get("/test-openai", async (req, res) => {
  try {
    console.log("ðŸ§ª Testing OpenAI API connection...");
    const models = await openai.models.list();
    console.log("âœ… OpenAI API connection successful");

    res.json({
      success: true,
      message: "OpenAI API connection successful",
      modelsCount: models.data.length,
      apiKeyConfigured: !!process.env.OPENAI_API_KEY,
    });
  } catch (error: any) {
    console.error("âŒ OpenAI API test failed:", error.message);
    res.status(500).json({
      success: false,
      error: "OpenAI API connection failed",
      details: error.message,
    });
  }
});

// ðŸš€ Start server
app.listen(port, () => {
  console.log(`ðŸš€ Server running at http://localhost:${port}`);
  console.log(`Store ID: ${VECTOR_STORE_ID}`);
  console.log(`OpenAI model: ${process.env.OPENAI_MODEL || "gpt-3.5-turbo"}`);
  console.log(`ðŸ§ª Test OpenAI API: http://localhost:${port}/test-openai`);
});
